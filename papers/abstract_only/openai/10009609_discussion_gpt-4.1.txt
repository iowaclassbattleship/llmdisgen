**Discussion**

This study sought to systematically assess the impact of UK-based oncology research on national cancer clinical guidelines by analysing citation patterns within guideline references and comparing them to the broader oncology literature. Our findings indicate a significant overrepresentation of UK research, with papers being cited nearly three times more frequently than would be expected based on the country's share of global oncology publication output during the reference period (1999–2001).

This substantial citation overrepresentation suggests that UK-based research has a disproportionately high influence on the evidence base for UK clinical guidelines. Such an effect aligns with the "instrumental use" of research delineated in the Research Impact Framework (Kuruvilla et al.), where research findings directly inform and drive policy and practice development. The use of locally conducted research in guideline formulation could reflect the perceived contextual relevance, accessibility, and policy resonance of this work within the UK health system, reinforcing the role of national research investment in shaping clinical practice standards.

Regionally, the marked contributions from Edinburgh and Glasgow, beyond what would be expected from their overall research output, point to centres of excellence or particular research specialisation—possibly supported by strong research infrastructure, collaborative culture, or specific funding streams. This regional emphasis warrants further investigation into the research environments and networks in these cities that facilitate high-impact research translation into policy.

Our analysis also revealed that UK guideline-cited papers acknowledged funding more explicitly and broadly than the average UK oncology research paper of the same period and research level. Enhanced funding transparency may correlate with research impact, possibly due to funding bodies' increasing emphasis on demonstrable real-world outcomes and the encouragement of publication practices that highlight funder contributions. It also suggests that funder requirements and funding mechanisms themselves may shape research trajectories towards clinical relevance and guideline inclusion.

The approach taken mirrors the emphasis of Kuruvilla et al.'s Research Impact Framework on systematised, multi-dimensional impact assessment. While our primary focus was on guideline citation—a policy-level impact—the framework's comprehensive typology (including research-related, service, and societal impacts) highlights that this metric captures only one facet of research impact. Nevertheless, guideline inclusion is a particularly robust proxy for practical clinical influence, given that guidelines both summarise and mandate best practice.

Our findings are subject to several limitations. Citation analysis, while objective, may not fully capture the nuances of research influence, such as contributions to conceptual change ("conceptual use") or mobilisation of support for policy proposals, as outlined in the Research Impact Framework. Additionally, not all influential research is cited in guidelines, and citation frequency can be influenced by authorship networks and local familiarity.

In conclusion, our study demonstrates the critical role of UK oncology research in shaping national clinical guidelines, with certain regions exerting significant influence and explicit funding acknowledgment being more frequent among high-impact papers. Establishing standardised, reproducible methods, as advocated by Kuruvilla et al., is essential for ongoing assessment and optimisation of research impact, not only in policy but across the broader spectrum of health and societal outcomes. Future work should further examine the mechanisms linking research investment, regional research capacity, and ultimate clinical and societal benefit.