**Discussion**

This study provides a systematic analysis of the relationship between UK biomedical research output in oncology and its citation within national clinical guidelines, offering valuable insight into the assessment of research impact on policy and practice. The overrepresentation of UK-authored oncological research in guideline references—nearly three times their proportion in global oncology output—demonstrates a strong influence of national research on the formation of practice guidelines. This highlights the particular impact of UK-based research efforts not only in advancing scientific understanding but in shaping clinical decision-making at a national level.

The observed prominence of cities such as Edinburgh and Glasgow in contributing to the guideline evidence base suggests regional centers of excellence and influence, which may be attributable to concentrated funding, expertise, or institutional commitment to translational and clinical research in oncology. This regional analysis could be of practical importance for future studies and policymakers seeking to foster impactful research environments.

A notable finding is the greater rate of explicit funding acknowledgments in UK guideline-cited papers compared to the background body of oncology research articles from the same period. This could reflect both an increased emphasis on funding transparency in research that is subsequently deemed policy-relevant, as well as greater investment in translating funded research into clinical practice recommendations. Such patterns underline the importance of broad-based support—across public, philanthropic, and private sectors—in maximizing the policy uptake of biomedical research.

In the context of existing literature, our findings complement frameworks such as the one described by Kuruvilla et al., who categorize research impact into several domains including policy and service impacts. Their Research Impact Framework also distinguishes between different types of policy influences—from direct instrumental use through to broader conceptual changes. Our results predominantly illustrate direct instrumental impact, wherein UK research is explicitly cited as the evidentiary basis for clinical guidelines. However, further work could interrogate whether UK oncology research also exerts conceptual or symbolic influence in shaping the discourse of guideline committees or mobilizing support for specific clinical approaches.

The methodology deployed in this study—systematic identification and comparison of research inputs to guideline formulation—aligns well with calls in the literature for standardized approaches to impact assessment (Kuruvilla et al.). Such approaches can help move beyond ad hoc accounts of research benefit to provide robust, comparable, and verifiable evidence of research influence on policy and practice.

There are limitations to be acknowledged. The predominance of UK research in UK guidelines may partly reflect a preferential citation of national rather than international research outputs, whether for reasons of perceived contextual relevance or easier accessibility. Additionally, measuring impact solely through citation in guidelines may underestimate broader influences, such as changes in research paradigms, indirect service improvements, or societal level outcomes as highlighted in the cited framework.

In conclusion, this national case study confirms that research impact on policy, in the form of citation in clinical guidelines, is both significant and measurable. The findings should encourage researchers, funders, and policy-makers to value and incentivize dissemination strategies that enhance the visibility and application of research, as well as to adopt structured impact assessment tools to capture a wide range of research benefits. Future studies should seek to broaden the measures of impact to encompass not only instrumental but also conceptual and societal contributions to healthcare improvement.