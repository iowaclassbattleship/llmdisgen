The proposed gait recognition approach demonstrates several noteworthy advantages over existing methods in both gait authentication and gait labeling tasks, as evidenced by the experimental results on two major public datasets (McGill and OU-ISIR). The integration of the novel Angle Embedded Gait Dynamic Image (AE-GDI) representation with convolutional neural networks (CNN) provides a robust and discriminative framework for harnessing inertial sensor data from wearable devices.

First, the AE-GDI effectively addresses the challenges associated with sensor orientation and translation variations, which are common in inertial sensor-based gait analysis. Unlike previous methods that only ensured statistical orientation invariance or relied on inner product-based features vulnerable to translation and scaling, the angle-based encoding uses linear transformation invariant properties that maintain robustness after normalization. This invariance is critical as it alleviates the impact of sensor position variations and preprocessing steps, thereby improving the stability of the gait representation. Empirically, this is supported by the clear discriminability of AE-GDIs across subjects, as shown in the visual comparisons and reflected in the improved recognition accuracy.

Second, converting the time-series inertial sensor data into a 2D image-like AE-GDI enables the application of powerful image classification techniques such as CNNs. The CNN architecture designed in this study, incorporating multiple convolutional and pooling layers followed by fully connected layers, automates hierarchical feature extraction without the need for handcrafted features, which are traditionally labor-intensive and dataset-specific. The observed performance gains demonstrate this advantage: the CNN-based framework outperformed non-parametric approaches relying on template matching or heuristic similarity measures in both same-day and cross-day authentication scenarios. Notably, leveraging CNNs allows efficient storage and computation through compact parametric models, in contrast to the computationally expensive non-parametric nearest neighbor searches.

Moreover, the proposed grid-based greedy gait cycle segmentation plays a fundamental role in aligning the AE-GDI generation with actual gait cycles. This segmentation method synergistically integrates global periodic constraints with local peak detection, enhancing the robustness and accuracy of gait cycle detection. The algorithm’s ability to handle sub-dominant peaks and maintain temporal properties without resampling or time-stretching retains meaningful dynamic features, which likely contributes to the improved performance relative to overlapping sliding window segmentation baselines.

The method’s efficacy is further supported by the analysis of hyperparameters such as the number of consecutive gait cycles used (parameter N) and the quantity of training samples, revealing practical guidelines for balancing recognition accuracy and computational cost. Increasing N generally improved accuracy, with the best results observed when using multiple consecutive gait cycles, suggesting stable gait patterns require sufficient temporal context for reliable identification.

The evaluations on the large-scale OU-ISIR dataset highlight the scalability of the proposed approach when applied to a multi-class labeling task with a substantial number of subjects (up to 744). Although the labeling accuracy naturally decreases as the number of subjects increases, the AE-GDI-based CNN approach maintains higher robustness and degrades more gracefully compared to temporal convolution baselines, indicating the superiority of the spatial-temporal features captured by the angle-embedded representation.

However, the approach also indicates potential limitations and areas for future improvement. Despite its linear transformation invariance, the AE-GDI remains sensitive to sensor placement variations, which can cause recognition degradation especially in unconstrained, real-world conditions. Future research should target enhancing placement invariance or robustness, possibly leveraging sensor fusion, adaptive modeling, or data augmentation strategies.

Additionally, given the success of recurrent neural networks in modeling temporal dependencies, integrating convolutional recurrent architectures with AE-GDI representations could further capture sequential dynamics and improve recognition performance. Also, exploring architectural refinements inspired by modern CNN designs (such as those embodied in Inception or residual networks, as seen in the literature) may provide improved representational power and efficiency.

In conclusion, the novel AE-GDI representation combined with CNNs provides a compelling framework for inertial sensor-based gait recognition, outperforming existing techniques in various settings and showing promise for practical wearable biometric applications. The approach’s robustness to orientation and translation changes, effective gait cycle segmentation, and proficiency in feature learning collectively contribute to its enhanced recognition accuracy and computational efficiency. Future work focusing on placement invariance and leveraging advanced deep learning architectures is warranted to further advance the state of gait recognition technology.